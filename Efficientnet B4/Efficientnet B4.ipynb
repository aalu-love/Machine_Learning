{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b29cf7e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T13:47:15.878275Z",
     "iopub.status.busy": "2022-06-05T13:47:15.877463Z",
     "iopub.status.idle": "2022-06-05T13:47:22.029660Z",
     "shell.execute_reply": "2022-06-05T13:47:22.030161Z",
     "shell.execute_reply.started": "2022-06-05T07:51:14.887708Z"
    },
    "papermill": {
     "duration": 6.179424,
     "end_time": "2022-06-05T13:47:22.030520",
     "exception": false,
     "start_time": "2022-06-05T13:47:15.851096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import PIL,cv2\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "from tensorflow.keras.applications import EfficientNetB4,ResNet50,EfficientNetB5\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED=48\n",
    "DEBUG=False\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU') \n",
    "# for gpu in gpus: \n",
    "#     tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aceecf87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T13:47:22.063996Z",
     "iopub.status.busy": "2022-06-05T13:47:22.063402Z",
     "iopub.status.idle": "2022-06-05T13:47:22.294293Z",
     "shell.execute_reply": "2022-06-05T13:47:22.293744Z",
     "shell.execute_reply.started": "2022-06-05T07:51:51.086686Z"
    },
    "papermill": {
     "duration": 0.248612,
     "end_time": "2022-06-05T13:47:22.294428",
     "exception": false,
     "start_time": "2022-06-05T13:47:22.045816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_PATH='../input/shopee-product-matching/'\n",
    "train=pd.read_csv(BASE_PATH+\"train.csv\")\n",
    "train['image_path']=BASE_PATH+'train_images/'+train.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b2c67d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T13:47:22.327937Z",
     "iopub.status.busy": "2022-06-05T13:47:22.327007Z",
     "iopub.status.idle": "2022-06-05T13:47:22.356443Z",
     "shell.execute_reply": "2022-06-05T13:47:22.356921Z",
     "shell.execute_reply.started": "2022-06-05T07:51:51.328723Z"
    },
    "papermill": {
     "duration": 0.050126,
     "end_time": "2022-06-05T13:47:22.357060",
     "exception": false,
     "start_time": "2022-06-05T13:47:22.306934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of Available Data\n",
      "         posting_id                                 image       image_phash  \\\n",
      "0   train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg  94974f937d4c2433   \n",
      "1  train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg  af3f9460c2838f0f   \n",
      "2  train_2288590299  000a190fdd715a2a36faed16e2c65df7.jpg  b94cb00ed3e50f78   \n",
      "3  train_2406599165  00117e4fc239b1b641ff08340b429633.jpg  8514fc58eafea283   \n",
      "4  train_3369186413  00136d1cf4edede0203f32f05f660588.jpg  a6f319f924ad708c   \n",
      "\n",
      "                                               title  label_group  \\\n",
      "0                          Paper Bag Victoria Secret    249114794   \n",
      "1  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...   2937985045   \n",
      "2        Maling TTS Canned Pork Luncheon Meat 397 gr   2395904891   \n",
      "3  Daster Batik Lengan pendek - Motif Acak / Camp...   4093212188   \n",
      "4                  Nescafe \\xc3\\x89clair Latte 220ml   3648931069   \n",
      "\n",
      "                                          image_path  label_number  \n",
      "0  ../input/shopee-product-matching/train_images/...             0  \n",
      "1  ../input/shopee-product-matching/train_images/...             1  \n",
      "2  ../input/shopee-product-matching/train_images/...             2  \n",
      "3  ../input/shopee-product-matching/train_images/...             3  \n",
      "4  ../input/shopee-product-matching/train_images/...             4   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "id_to_label_mapping=dict(zip(train.label_group.unique(),range(train.label_group.nunique())))\n",
    "train[\"label_number\"]=train.label_group.map(id_to_label_mapping)\n",
    "\n",
    "NUM_CLASSES=train.label_group.nunique()\n",
    "HEIGHT,WIDTH=128,128\n",
    "CHANNELS=3\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE=40\n",
    "\n",
    "print(\"Sample of Available Data\")\n",
    "print(train.head(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "247a35f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T13:47:22.389284Z",
     "iopub.status.busy": "2022-06-05T13:47:22.388473Z",
     "iopub.status.idle": "2022-06-05T13:47:22.390498Z",
     "shell.execute_reply": "2022-06-05T13:47:22.390908Z",
     "shell.execute_reply.started": "2022-06-05T07:51:51.369879Z"
    },
    "papermill": {
     "duration": 0.020556,
     "end_time": "2022-06-05T13:47:22.391049",
     "exception": false,
     "start_time": "2022-06-05T13:47:22.370493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data processing function for creating tf.data dataset \n",
    "# Converting image path dataset to image label dataset\n",
    "def process_data(image_path,label):\n",
    "    img=tf.io.read_file(image_path)\n",
    "    img=tf.image.decode_jpeg(img,channels=CHANNELS)\n",
    "    img=tf.image.resize(img,[HEIGHT,WIDTH])\n",
    "    return img,label\n",
    "\n",
    "# function to improve dataset processing speed \n",
    "def configure_for_performance(ds,batch_size):\n",
    "    ds=ds.cache('/kaggle/dump.tfcache')\n",
    "    \n",
    "    ds=ds.shuffle(buffer_size=1024)\n",
    "    ds=ds.batch(BATCH_SIZE)\n",
    "    ds=ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12dfdfe4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T13:47:22.419307Z",
     "iopub.status.busy": "2022-06-05T13:47:22.418465Z",
     "iopub.status.idle": "2022-06-05T13:47:25.202963Z",
     "shell.execute_reply": "2022-06-05T13:47:25.202308Z",
     "shell.execute_reply.started": "2022-06-05T07:51:51.382068Z"
    },
    "papermill": {
     "duration": 2.799865,
     "end_time": "2022-06-05T13:47:25.203131",
     "exception": false,
     "start_time": "2022-06-05T13:47:22.403266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-05 13:47:22.511688: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-05 13:47:22.620070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-05 13:47:22.620968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset before reconfiguring\n",
      "train data: tf.Tensor(30825, shape=(), dtype=int64)\n",
      "valid data tf.Tensor(3425, shape=(), dtype=int64) \n",
      "\n",
      "Dataset after reconfiguring(BATCH+SHUFFLE+PREFETCH)\n",
      "train data: tf.Tensor(771, shape=(), dtype=int64)\n",
      "valid data tf.Tensor(429, shape=(), dtype=int64) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-05 13:47:22.624265: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-05 13:47:22.625501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-05 13:47:22.626438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-05 13:47:22.627244: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-05 13:47:24.736534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-05 13:47:24.737485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-05 13:47:24.738177: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-05 13:47:24.738802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "x_train,x_valid=train_test_split(train,test_size=0.1,random_state=SEED,shuffle=True)\n",
    "\n",
    "# image path & label dataset\n",
    "train_ds=tf.data.Dataset.from_tensor_slices((x_train.image_path.values,x_train.label_number.values))\n",
    "valid_ds=tf.data.Dataset.from_tensor_slices((x_valid.image_path.values,x_valid.label_number.values))\n",
    "\n",
    "# image & label dataset\n",
    "train_ds=train_ds.map(process_data,num_parallel_calls=AUTOTUNE)\n",
    "valid_ds=valid_ds.map(process_data,num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# improving dataset by shuffling dataset,creating image batch and prefetching dataset\n",
    "# more information : https://www.tensorflow.org/guide/data_performance\n",
    "# Batch image and label dataset\n",
    "train_ds_batch = configure_for_performance(train_ds, 8)\n",
    "valid_ds_batch = valid_ds.batch(8)\n",
    "\n",
    "print(\"Dataset before reconfiguring\")\n",
    "print(\"train data:\",train_ds.cardinality())\n",
    "print(\"valid data\",valid_ds.cardinality(),'\\n')\n",
    "\n",
    "print(\"Dataset after reconfiguring(BATCH+SHUFFLE+PREFETCH)\")\n",
    "print(\"train data:\",train_ds_batch.cardinality())\n",
    "print(\"valid data\",valid_ds_batch.cardinality(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac6020c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T13:47:25.238207Z",
     "iopub.status.busy": "2022-06-05T13:47:25.237355Z",
     "iopub.status.idle": "2022-06-05T13:47:25.239611Z",
     "shell.execute_reply": "2022-06-05T13:47:25.240048Z",
     "shell.execute_reply.started": "2022-06-05T07:51:57.316232Z"
    },
    "papermill": {
     "duration": 0.022377,
     "end_time": "2022-06-05T13:47:25.240198",
     "exception": false,
     "start_time": "2022-06-05T13:47:25.217821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to get our f1 score\n",
    "def f1_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    len_y_pred = y_pred.apply(lambda x: len(x)).values\n",
    "    len_y_true = y_true.apply(lambda x: len(x)).values\n",
    "    f1 = 2 * intersection / (len_y_pred + len_y_true)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c739430a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T13:47:25.276377Z",
     "iopub.status.busy": "2022-06-05T13:47:25.275608Z",
     "iopub.status.idle": "2022-06-05T13:47:25.277884Z",
     "shell.execute_reply": "2022-06-05T13:47:25.278320Z",
     "shell.execute_reply.started": "2022-06-05T07:51:57.324953Z"
    },
    "papermill": {
     "duration": 0.023178,
     "end_time": "2022-06-05T13:47:25.278459",
     "exception": false,
     "start_time": "2022-06-05T13:47:25.255281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pairwise_distances(embeddings):\n",
    "    dot_product = tf.linalg.matmul(embeddings, tf.transpose(embeddings))\n",
    "    square_norm = tf.linalg.diag_part(dot_product)\n",
    "    distances = tf.expand_dims(square_norm, 1) - 2.0 * dot_product + tf.expand_dims(square_norm, 0)\n",
    "    distances = tf.math.maximum(distances, 0.0)\n",
    "\n",
    "    mask = tf.cast(tf.equal(distances, 0.0),tf.float32)\n",
    "    distances = distances + mask * 1e-16\n",
    "    distances = tf.math.sqrt(distances)\n",
    "    distances = distances * (1.0 - mask)\n",
    "\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e5f65e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T13:47:25.311645Z",
     "iopub.status.busy": "2022-06-05T13:47:25.310794Z",
     "iopub.status.idle": "2022-06-05T13:47:25.313192Z",
     "shell.execute_reply": "2022-06-05T13:47:25.312803Z",
     "shell.execute_reply.started": "2022-06-05T07:51:57.338081Z"
    },
    "papermill": {
     "duration": 0.020496,
     "end_time": "2022-06-05T13:47:25.313330",
     "exception": false,
     "start_time": "2022-06-05T13:47:25.292834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_anchor_positive_triplet_mask(labels):\n",
    "    indices_equal = tf.cast(tf.eye(tf.shape(labels)[0]), tf.bool)\n",
    "    indices_not_equal = tf.math.logical_not(indices_equal)\n",
    "\n",
    "    labels_equal = tf.math.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "    mask = tf.math.logical_and(indices_not_equal, labels_equal)\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43ef8846",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T13:47:25.343887Z",
     "iopub.status.busy": "2022-06-05T13:47:25.343071Z",
     "iopub.status.idle": "2022-06-05T13:47:25.347765Z",
     "shell.execute_reply": "2022-06-05T13:47:25.347337Z",
     "shell.execute_reply.started": "2022-06-05T07:51:57.346628Z"
    },
    "papermill": {
     "duration": 0.020854,
     "end_time": "2022-06-05T13:47:25.347873",
     "exception": false,
     "start_time": "2022-06-05T13:47:25.327019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_anchor_negative_triplet_mask(labels):\n",
    "    labels_equal = tf.math.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "    mask = tf.math.logical_not(labels_equal)\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7709c4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T13:47:25.382221Z",
     "iopub.status.busy": "2022-06-05T13:47:25.381257Z",
     "iopub.status.idle": "2022-06-05T13:47:25.383369Z",
     "shell.execute_reply": "2022-06-05T13:47:25.383766Z",
     "shell.execute_reply.started": "2022-06-05T07:51:57.359184Z"
    },
    "papermill": {
     "duration": 0.022258,
     "end_time": "2022-06-05T13:47:25.383908",
     "exception": false,
     "start_time": "2022-06-05T13:47:25.361650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_triplet_mask(labels):\n",
    "    indices_equal = tf.cast(tf.eye(tf.shape(labels)[0]), tf.bool)\n",
    "    indices_not_equal = tf.math.logical_not(indices_equal)\n",
    "    i_not_equal_j = tf.expand_dims(indices_not_equal, 2)\n",
    "    i_not_equal_k = tf.expand_dims(indices_not_equal, 1)\n",
    "    j_not_equal_k = tf.expand_dims(indices_not_equal, 0)\n",
    "\n",
    "    distinct_indices = tf.math.logical_and(tf.math.logical_and(i_not_equal_j, i_not_equal_k), j_not_equal_k)\n",
    "\n",
    "\n",
    "    label_equal = tf.math.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "    i_equal_j = tf.expand_dims(label_equal, 2)\n",
    "    i_equal_k = tf.expand_dims(label_equal, 1)\n",
    "\n",
    "    valid_labels = tf.math.logical_and(i_equal_j, tf.logical_not(i_equal_k))\n",
    "\n",
    "    mask = tf.math.logical_and(distinct_indices, valid_labels)\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67924be4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T13:47:25.421658Z",
     "iopub.status.busy": "2022-06-05T13:47:25.420947Z",
     "iopub.status.idle": "2022-06-05T13:47:25.422993Z",
     "shell.execute_reply": "2022-06-05T13:47:25.423488Z",
     "shell.execute_reply.started": "2022-06-05T07:51:57.372763Z"
    },
    "papermill": {
     "duration": 0.025459,
     "end_time": "2022-06-05T13:47:25.423611",
     "exception": false,
     "start_time": "2022-06-05T13:47:25.398152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TripletLossFn(tf.keras.losses.Loss):\n",
    "    def __init__(self,margin=1.0,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.margin = margin\n",
    "  \n",
    "    def call(self,y_true,y_pred):\n",
    "\n",
    "        labels = tf.convert_to_tensor(y_true)\n",
    "        labels = tf.squeeze(labels,axis=-1)\n",
    "        embeddings = tf.convert_to_tensor(y_pred)\n",
    "\n",
    "        pairwise_dist = pairwise_distances(embeddings)\n",
    "\n",
    "        mask_anchor_positive = get_anchor_positive_triplet_mask(labels)\n",
    "        mask_anchor_positive = tf.cast(mask_anchor_positive,tf.float32)\n",
    "\n",
    "        anchor_positive_dist = tf.math.multiply(mask_anchor_positive, pairwise_dist)\n",
    "\n",
    "        hardest_positive_dist = tf.math.reduce_max(anchor_positive_dist, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "        mask_anchor_negative = get_anchor_negative_triplet_mask(labels)\n",
    "        mask_anchor_negative = tf.cast(mask_anchor_negative,tf.float32)\n",
    "\n",
    "        max_anchor_negative_dist = tf.math.reduce_max(pairwise_dist, axis=1, keepdims=True)\n",
    "        anchor_negative_dist = pairwise_dist + max_anchor_negative_dist * (1.0 - mask_anchor_negative)\n",
    "\n",
    "\n",
    "        hardest_negative_dist = tf.math.reduce_min(anchor_negative_dist, axis=1, keepdims=True)\n",
    "    \n",
    "\n",
    "        triplet_loss = tf.math.maximum(hardest_positive_dist - hardest_negative_dist + self.margin, 0.0)\n",
    "\n",
    "        triplet_loss = tf.math.reduce_mean(triplet_loss)\n",
    "\n",
    "        return triplet_loss\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config,\"margin\":self.margin}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6116bd2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T13:47:25.461500Z",
     "iopub.status.busy": "2022-06-05T13:47:25.460684Z",
     "iopub.status.idle": "2022-06-05T13:47:25.463159Z",
     "shell.execute_reply": "2022-06-05T13:47:25.462719Z",
     "shell.execute_reply.started": "2022-06-05T07:51:57.387256Z"
    },
    "papermill": {
     "duration": 0.026303,
     "end_time": "2022-06-05T13:47:25.463327",
     "exception": false,
     "start_time": "2022-06-05T13:47:25.437024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model creation using a pretrained model\n",
    "def create_model(pretrained_model):  \n",
    "    \n",
    "    model=tf.keras.Sequential([\n",
    "        pretrained_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# funtion to compile a choosen model\n",
    "def compile_model(model,LR=0.001):\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(lr=LR)\n",
    "    \n",
    "    loss=TripletLossFn(0.7)\n",
    "    \n",
    "    metrics = [\n",
    "       tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    ]\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Callback list generation\n",
    "def callback_creation(model_path):\n",
    "    \n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        factor=0.1,\n",
    "        patience=3,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=model_path,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        patience=10, \n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    callbacks=[reduce_lr,model_checkpoint,early_stopping]\n",
    "    \n",
    "    return callbacks\n",
    "\n",
    "# model training\n",
    "def model_training(pretrained_model,model_path):\n",
    "    EPOCH_COUNTS=1\n",
    "    VERBOSE=1\n",
    "    LR=0.0001\n",
    "\n",
    "    tf.keras.backend.clear_session();\n",
    "\n",
    "    model=create_model(pretrained_model)\n",
    "    model=compile_model(model,LR=LR)\n",
    "    callback_list=callback_creation(model_path)\n",
    "\n",
    "\n",
    "    history=model.fit(\n",
    "                        train_ds_batch,\n",
    "                        validation_data=valid_ds_batch,\n",
    "                        epochs=EPOCH_COUNTS,\n",
    "                        callbacks=callback_list,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb0b33ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-05T13:47:25.499198Z",
     "iopub.status.busy": "2022-06-05T13:47:25.498601Z",
     "iopub.status.idle": "2022-06-05T13:51:36.540700Z",
     "shell.execute_reply": "2022-06-05T13:51:36.541183Z"
    },
    "papermill": {
     "duration": 251.062608,
     "end_time": "2022-06-05T13:51:36.541396",
     "exception": false,
     "start_time": "2022-06-05T13:47:25.478788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb4_notop.h5\n",
      "71688192/71686520 [==============================] - 0s 0us/step\n",
      "71696384/71686520 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
      "2022-06-05 13:47:42.606593: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-06-05 13:47:52.930423: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/771 [===========================>..] - ETA: 6s - loss: 0.0035"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-05 13:51:09.356627: W tensorflow/core/kernels/data/cache_dataset_ops.cc:233] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "771/771 [==============================] - 244s 279ms/step - loss: 0.0034 - val_loss: 6.7838e-04\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00068, saving model to ./best_model_efnb4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "efnb4_model_path='./best_model_efnb4.h5'\n",
    "pretrained_model=EfficientNetB4(include_top=False, weights='imagenet',input_shape=[HEIGHT,WIDTH, 3])\n",
    "model_training(pretrained_model,efnb4_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 272.513614,
   "end_time": "2022-06-05T13:51:40.028471",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-05T13:47:07.514857",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
